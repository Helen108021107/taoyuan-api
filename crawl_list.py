import requests
import pandas as pd
import os
import concurrent.futures
import urllib3
import time

# é—œé–‰ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# åŸå§‹æª”èˆ‡è¼¸å‡ºæª”
ORIGINAL_CSV = os.path.join(BASE_DIR, "data", "statistics.csv")
OUTPUT_CSV = os.path.join(BASE_DIR, "data", "statistics_full.csv")

BASE_URL = "https://statisticsinfo.tycg.gov.tw/TaoyuanSTYB/RestfulAPI/GetStaticData.aspx"

# è¨­å®šæƒæç¯„åœ
# æ ¹æ“šæ‚¨çš„ç™¼ç¾ï¼Œtid=0005 è£¡é¢æœ‰ cid=0002ï¼Œæ‰€ä»¥æˆ‘å€‘è¦åŠ å¼·æƒæ
TIDS = ["0001", "0002", "0003", "0004", "0005"]
CIDS = [f"{i:04d}" for i in range(1, 25)]  # æƒæ 0001~0024 é¡åˆ¥
SIDS = [f"{i:06d}" for i in range(1, 40)]  # æƒææ¯å€‹é¡åˆ¥çš„å‰ 40 å€‹é …ç›®

def check_url(tid, cid, sid):
    """æ¸¬è©¦å–®ä¸€çµ„åˆæ˜¯å¦æœ‰æ•ˆ"""
    params = {
        "tid": tid, "cid": cid, "sid": sid,
        "begin": "2023", "end": "2024", "type": "JSON"
    }
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    try:
        # è¨­å®š timeout ç‚º 2 ç§’ï¼ŒåŠ å¿«æƒæé€Ÿåº¦
        response = requests.get(BASE_URL, params=params, headers=headers, verify=False, timeout=2)
        
        # åªè¦ä¸æ˜¯ç©ºçš„ä¸”ç‹€æ…‹æ˜¯ 200ï¼Œå°±è¦–ç‚ºæœ‰æ•ˆ
        if response.status_code == 200 and len(response.text.strip()) > 5:
            try:
                data = response.json()
                # æ’é™¤ç©ºé™£åˆ— []
                if isinstance(data, list) and len(data) > 0:
                    # å˜—è©¦æŠ“å–æ¨™é¡Œï¼Œé€šå¸¸æ˜¯ JSON Key çš„ä¸€éƒ¨åˆ†ï¼Œæˆ–æ˜¯æˆ‘å€‘åªèƒ½æ¨™è¨˜å®ƒæ˜¯ã€ŒæœªçŸ¥é …ç›®ã€
                    first_row = data[0]
                    # ç°¡æ˜“æ‹¼æ¹Šä¸€å€‹åç¨±ï¼Œè®“æ‚¨å¯ä»¥æœå°‹åˆ°
                    name_guess = f"[è‡ªå‹•ç™¼ç¾] é …ç›®_{tid}_{cid}_{sid}"
                    
                    # å˜—è©¦å¾è³‡æ–™å…§å®¹æ‰¾ç·šç´¢ (æœ‰äº›è³‡æ–™æœƒæœ‰ 'Item' æ¬„ä½)
                    if 'Item' in first_row: name_guess = first_row['Item']
                    
                    print(f"âœ… ç™¼ç¾è³‡æ–™: tid={tid} cid={cid} sid={sid} | é è¦½: {str(first_row)[:30]}...")
                    
                    return {
                        "æ‰€å±¬è³‡æ–™åº«": f"è³‡æ–™åº«_{tid}",
                        "tid": tid,
                        "æ‰€å±¬é¡åˆ¥": f"é¡åˆ¥_{cid}",
                        "cid": cid,
                        "è³‡æ–™åç¨±": name_guess,
                        "sid": sid,
                        "çµ±è¨ˆè³‡æ–™æª”æ¡ˆæ ¼å¼": response.url
                    }
            except:
                pass
    except:
        pass
    return None

def main():
    print(f"ğŸš€ é–‹å§‹ Antigravity çˆ¬èŸ²æƒæ... (ç›®æ¨™: {OUTPUT_CSV})")
    print("é€™å°‡æœƒæƒææ•¸åƒå€‹çµ„åˆï¼Œè«‹ç¨å€™...")
    
    new_records = []
    
    # ä½µç™¼åŸ·è¡Œæƒæ
    with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:
        futures = []
        for tid in TIDS:
            for cid in CIDS:
                for sid in SIDS:
                    futures.append(executor.submit(check_url, tid, cid, sid))
        
        for future in concurrent.futures.as_completed(futures):
            result = future.result()
            if result:
                new_records.append(result)

    print(f"\nâœ… æƒæå®Œæˆï¼å…±ç™¼ç¾ {len(new_records)} ç­†æœ‰æ•ˆè³‡æ–™ã€‚")

    # åˆä½µèˆŠè³‡æ–™
    all_data = []
    if os.path.exists(ORIGINAL_CSV):
        try:
            old_df = pd.read_csv(ORIGINAL_CSV)
            # çµ±ä¸€æ¬„ä½å‹æ…‹
            old_df['tid'] = old_df['tid'].astype(str).str.zfill(4)
            old_df['cid'] = old_df['cid'].astype(str).str.zfill(4)
            old_df['sid'] = old_df['sid'].astype(str).str.zfill(6)
            all_data.append(old_df)
            print("å·²è¼‰å…¥åŸå§‹ CSV è³‡æ–™ã€‚")
        except Exception as e:
            print(f"åŸå§‹ CSV è®€å–å¤±æ•—: {e}")

    if new_records:
        new_df = pd.DataFrame(new_records)
        all_data.append(new_df)

    if all_data:
        # åˆä½µä¸¦ç§»é™¤é‡è¤‡ (å„ªå…ˆä¿ç•™åŸæœ¬æœ‰çš„)
        final_df = pd.concat(all_data)
        # æ ¹æ“š ID å»é™¤é‡è¤‡
        final_df.drop_duplicates(subset=['tid', 'cid', 'sid'], keep='first', inplace=True)
        
        # å­˜æª”
        final_df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8-sig')
        print(f"ğŸ‰ å®Œæ•´æ¸…å–®å·²å„²å­˜è‡³: {OUTPUT_CSV}")
        print("ç¾åœ¨è«‹é‡æ–°å•Ÿå‹•æ‚¨çš„ MCP Server (server.py)ï¼Œå®ƒå°‡æœƒè®€å–é€™å€‹æ–°æª”æ¡ˆã€‚")
    else:
        print("âš ï¸ æ²’ç™¼ç¾ä»»ä½•è³‡æ–™ï¼Œè«‹æª¢æŸ¥ç¶²è·¯ã€‚")

if __name__ == "__main__":
    main()